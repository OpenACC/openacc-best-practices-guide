Introduction
============
本ガイドでは、アプリケーションを段階的かつパフォーマンス・ポータブルな方法で高速化する手法とベストプラクティスを紹介します。一部の例では特定のコンパイラやアクセラレータを使用した結果を示すことがありますが、本書で提示される情報は、発行時点で利用可能なすべてのアーキテクチャだけでなく、将来にわたっても対応することを意図しています。読者はC、C++、またはFortranに精通していることが望ましいですが、並列プログラミングやアクセラレーテッド・コンピューティングの経験は必須ではありません。ただし、そのような経験があれば役立ちます。

注：本ガイドはコミュニティの取り組みです。貢献するには、[Github上のプロジェクト](https://github.com/OpenACC/openacc-best-practices-guide)をご覧ください。

ポータブルなコードの記述
---------------------
現在のコンピューティング環境には、マルチコアCPU、GPU、メニーコアデバイス、DSP、ARMプロセッサ、FPGAなど、さまざまなコンピューティング・アーキテクチャが点在しています。現在では、同一マシン内に1つだけでなく、これらの異なるアーキテクチャのいくつかが存在することが一般的です。プログラマーは、コードの移植性を事前に考慮しなければなりません。さもなければ、アプリケーションを単一のアーキテクチャに固定してしまうリスクがあり、将来のアーキテクチャで実行する能力を制限する可能性があります。アーキテクチャの多様性はプログラマーにとって困難に思えるかもしれませんが、詳しく分析すると、それらの間に多くの共通点を示す傾向が明らかになります。まず最初に注目すべきは、これらのアーキテクチャはすべて並列性の向上に向かっているということです。CPUはCPUコアを追加するだけでなく、SIMD演算の長さも拡張しています。GPUは、高度なブロックおよびSIMT並列性を必要とするまでに成長しています。今後、すべてのアーキテクチャで高性能を達成するためには、かなりの程度の並列性が必要になることは明らかです。最新のプロセッサは、大量の並列性だけでなく、さまざまな粒度の複数レベルの並列性を露出することが多くあります。次に注目すべきは、これらのアーキテクチャはすべてメモリの階層を露出していることです。CPUには、メインのシステムメモリ（通常はDDR）と複数層のキャッシュメモリがあります。GPUには、メインのCPUメモリ、メインのGPUメモリ、そしてさまざまな程度のキャッシュまたはスクラッチパッドメモリがあります。さらに、2つ以上の異なるアーキテクチャを含むハイブリッド・アーキテクチャには、2つのアーキテクチャが完全に別個のメモリを持つマシン、物理的には別々だが論理的には同じメモリを持つもの、そして完全に共有されたメモリを持つものが存在します。

これらの複雑さのため、開発者は移植性の必要性とパフォーマンスの必要性のバランスをとるプログラミングモデルを選択することが重要です。以下は、移植性とパフォーマンスの両方の程度が異なる4つのプログラミングモデルです。実際のアプリケーションでは、高い移植性とパフォーマンスの間で良好なバランスを確保するために、アプローチを混合して使用することが最適な場合が多くあります。

### ライブラリ ###

標準（および*事実上の*標準）ライブラリは、プログラマーがコンピューティング・アーキテクチャを変更する際に、ソースコード自体を変更することなく、使用するライブラリのみを置き換えることができるため、最高度の移植性を提供します。多くのハードウェアベンダーが一般的なライブラリの高度に最適化されたバージョンを提供しているため、ライブラリを使用することは非常に高いパフォーマンスをもたらすこともできます。ライブラリは高い移植性と高いパフォーマンスの両方を提供できますが、その限定的な範囲のため、ライブラリのみを使用できるアプリケーションはほとんどありません。
    
一部のベンダーは、自社のプラットフォーム向けの付加価値として追加のライブラリを提供していますが、これらは非標準のAPIを実装しています。これらのライブラリは高いパフォーマンスを提供しますが、移植性はほとんどありません。幸いなことに、ライブラリはモジュール式のAPIを提供するため、非移植性のライブラリを使用することの影響を分離して、アプリケーション全体の移植性への影響を制限することができます。

### 標準プログラミング言語 ###

多くの標準プログラミング言語は、並列プログラミングのための機能を持っているか、採用し始めています。たとえば、Fortran 2008は`do concurrent`のサポートを追加し、そのループ内の潜在的な並列性を露出しました。また、C++17は`std::execution`のサポートを追加し、特定のループ構造で並列性を表現できるようにしました。しかし、これらの言語機能の採用は遅いことが多く、多くの標準言語は、将来の言語リリースのための並列プログラミング機能について、ようやく議論を始めたばかりです。これらの機能が一般的になると、標準言語の一部であるため高い移植性を提供し、適切に設計されていれば高いパフォーマンスも提供できます。

### コンパイラディレクティブ ###

標準プログラミング言語に必要な機能のサポートが欠けている場合、コンパイラディレクティブが追加の機能を提供できます。ディレクティブは、C/C++ではプラグマの形式で、Fortranではコメントの形式で、コンパイラにコードの構築方法や最適化方法に関する追加情報を提供します。ほとんどのコンパイラは独自のディレクティブをサポートしており、また業界団体によって支援され、さまざまなコンパイラによって実装されているOpenACCやOpenMPなどのディレクティブもサポートしています。業界支援のコンパイラディレクティブを使用する場合、プログラマーはコンパイラとアーキテクチャ全体で高い移植性を持つコードを書くことができます。ただし、これらのコンパイラディレクティブは、単純性と移植性の両方のために非常に高レベルに留まるように書かれていることが多く、パフォーマンスは低レベルのプログラミングパラダイムに遅れを取る可能性があります。多くの開発者は、他のアーキテクチャへの高い移植性を得て、プログラマーの生産性を向上させるために、手動で最適化されたパフォーマンスの10〜20%を犠牲にすることをいとわないでしょう。この移植性とパフォーマンスのトレードオフに対する許容度は、プログラマーとアプリケーションのニーズに応じて異なります。

### 並列プログラミング拡張 ###

CUDAとOpenCLは、既存のプログラミング言語に追加の並列プログラミング機能を提供する拡張の例です。これらの言語で書かれたコードは、他のオプションよりも低レベルであることが多いですが、その結果、より高いパフォーマンスを達成できることが多くあります。低レベルのアーキテクチャの詳細が露出され、問題がハードウェアに分解される方法は、これらの言語で明示的に管理する必要があります。パフォーマンスの目標が移植性よりも優先される場合、これが最良のオプションです。これらのプログラミング言語の低レベルな性質により、結果として得られるコードはしばしば移植性が低くなります。優れたソフトウェアエンジニアリングの実践により、これらの言語が移植性に与える影響を軽減することができます。

----

すべてのニーズに適合する単一のプログラミングモデルはありません。アプリケーション開発者は、プロジェクトの優先順位を評価し、それに応じて決定を下す必要があります。ベストプラクティスは、最も移植性が高く生産的なプログラミングモデルから始めて、必要に応じてモジュール式の方法で低レベルのプログラミングモデルに移行することです。そうすることで、プログラマーはアプリケーションの多くを非常に迅速に高速化できます。これは、次に進む前に特定のルーチンから絶対的に最高のパフォーマンスを得ようとするよりも、しばしば有益です。開発時間が限られている場合、できるだけ多くのアプリケーションを高速化することに焦点を当てることは、一般的に、最も時間を消費するルーチンのみに焦点を当てるよりも生産的です。

OpenACCとは何か？
----------------
高性能コンピューティングにおけるGPUおよびメニーコア・アーキテクチャの出現により、プログラマーは、馴染みのある高レベルのプログラミングモデルを使用してプログラミングする能力を望んでいます。このモデルは、高いパフォーマンスと幅広いコンピューティング・アーキテクチャへの移植性の両方を提供します。OpenACCは2011年に、高レベルのコンパイラディレクティブを使用してコード内の並列性を露出し、並列化コンパイラを使用してさまざまな並列アクセラレータ向けにコードを構築するプログラミングモデルとして登場しました。本書は、OpenACCを使用してアプリケーションを高速化し、他のデバイスへの良好なパフォーマンスと移植性の両方を提供するためのベストプラクティスガイドとして意図されています。

### OpenACCアクセラレータモデル ###
OpenACCが、その開始時点で利用可能なすべてのコンピューティング・アーキテクチャおよび将来に向けて移植可能であることを保証するために、OpenACCはアクセラレーテッド・コンピューティングのための抽象モデルを定義しています。このモデルは、プロセッサに現れる可能性のある複数レベルの並列性と、さまざまな速度とアドレス可能性を持つメモリの階層を露出します。このモデルの目標は、OpenACCが特定のアーキテクチャや、その時点で広く利用可能なアーキテクチャだけでなく、将来のデバイスでも使用できることを保証することです。

その中核として、OpenACCは*ホスト*デバイスから*アクセラレータ*デバイスへの計算とデータの両方のオフロードをサポートします。実際、これらのデバイスは同じである場合もあれば、CPUホストとGPUアクセラレータの場合のように、完全に異なるアーキテクチャである場合もあります。2つのデバイスは、別個のメモリスペースを持つ場合もあれば、単一のメモリスペースを持つ場合もあります。2つのデバイスが異なるメモリを持つ場合、OpenACCコンパイラとランタイムはコードを分析し、アクセラレータのメモリ管理とホストとデバイスメモリ間のデータ転送を処理します。図1.1は、OpenACC抽象アクセラレータの高レベルの図を示していますが、一部のアーキテクチャでは、デバイスとメモリが物理的に同じである可能性があることを覚えておいてください。

![OpenACCの抽象アクセラレータモデル](images/execution_model2.png)

OpenACCの抽象アクセラレータモデルの詳細については、このガイド全体を通じて、関連する場合に紹介されます。

----

***ベストプラクティス：*** CUDAやOpenCLなどの他のアクセラレータ・プログラミングモデルからOpenACCに移行する開発者にとって、ホストとアクセラレータのメモリが頻繁に2つの異なる変数（たとえば、`host_A[]`と`device_A[]`）で表される場合、OpenACCを使用する場合、変数は、1つまたは複数のメモリスペースに支えられているかどうかにかかわらず、単一のオブジェクトとして考えるべきであることを覚えておくことが重要です。変数がプログラム内で使用される場所に応じて、2つの別個のメモリを表すと仮定すると、安全でない方法で変数にアクセスするプログラムを書く可能性があり、ホストとデバイス間で単一のメモリを共有するデバイスに移植できないコードになる可能性があります。並列または非同期のプログラミングパラダイムと同様に、コードの2つのセクションから同時に同じ変数にアクセスすると、一貫性のない結果を生成する競合状態が発生する可能性があります。メモリにどのように保存されているかにかかわらず、常に単一の変数にアクセスしていると仮定することで、プログラマーはデバッグにかなりの労力を要する可能性のある間違いを避けることができます。

### OpenACCの利点と制限 ###
OpenACCは、アクセラレータをプログラミングするための高レベルでプラットフォームに依存しない言語として設計されています。そのため、さまざまなデバイスで実行でき、良好なパフォーマンスを達成できる単一のソースコードを開発できます。OpenACCのプログラミングモデルが提供する単純性と移植性は、時にはパフォーマンスのコストを伴います。OpenACC抽象アクセラレータモデルは、アクセラレータデバイスの最小公倍数を定義しますが、言語の移植性を低下させることなく、これらのデバイスのアーキテクチャ固有の詳細を表現することはできません。CUDAやOpenCLなどの低レベルのプログラミングモデルでは可能だが、高レベルでは表現できない最適化が常に存在します。たとえば、OpenACCには`cache`ディレクティブがありますが、NVIDIA GPUの*共有メモリ*の一部の使用法は、CUDAを使用してより簡単に表現できます。同じことが、どのホストまたはデバイスにも当てはまります。特定の最適化は、OpenACCのような高レベルのアプローチには低レベルすぎます。選択的に低レベルのプログラミング言語をパフォーマンスクリティカルなコードセクションに使用することのコストと利益を決定するのは、開発者次第です。パフォーマンスが高レベルのアプローチを取るには重要すぎる場合でも、相互運用性に関する後の章で説明されるように、アプリケーションの多くにOpenACCを使用し、特定の場所で別のアプローチを使用することは可能です。
